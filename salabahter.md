# ÄŒIÅ Ä†ENJE PODATAKA
Q: Koje smo vrste problema u podacima identificirali u prvom dijelu projekta?

A:
- konstantne vrijednosti - uklonili smo tehniÄki stupac index
- nismo naÅ¡li monotone vrijednosti
- nadomjestili smo nepostojeÄ‡e vrijednosti
    - date_unregistration - -1 za nepostojeÄ‡i zapis
    - datum registracije - zamjenjen medijanom
    - clicks_pre_start, clicks_post_start, clicks_total - ispunjeni s 0
    - first_assignment_score - -1 za nedostjajuÄ‡u vrijednost + posebna bool varijabla za provjeru je li student predao ili nije prvi zadatak
    - socioekonomski status - zamjenjeni nakÄeÅ¡Ä‡om vrijednoÅ¡Ä‡u

Q: Kako smo odredili first_assignment?

A: Poredali smo sve zadatke koji nemaju vrstu "exam" po datumu i za svakog studenta uzeli prvi.

Q: Kako smo konstruirali varijablu clicks_pre_start?

A: Zbrojili smo sve klikove za jednog studenta za datume  manje od 0 (0 oznaÄava poÄetak studija)

Q: Kako smo uÄitali podatke iz 2. dijela projekta?

A: Izvezli smo oÄiÅ¡Ä‡ene pdoatke u .csv kojeg smo Äitali za 3. dio projekta.

Q: Koje smo zaÄajke transformirali iz kategoriÄkih u numeriÄke i kako?

A:
- 2 binarne znaÄajke gender_num i disability_num preslikali u 1/0
- socioekonomski status, stupanj edukacije, dob - jednostavno enumerirali

Q: Kako smo normalizirali podatke?

A: scikit MinMaxScaler pri pripremi podataka, za BART takoÄ‘er StandardScaler

- MinMaxScaler - skalira podatke da budu u rasponu [0,1]
- StandardScaler - normalizira podatke da spadaju unutar normalne razdiobe

# Kovarijacijska matrica

Q: Kako ste ispitali linearni odnos izmeÄ‘u ulaznih varijabli i ciljne varijable?

A: Pearsonova korelacijska analiza

Q: Å to ste zakljuÄili iz kovarijacijske matrice?

A: Korelacijski koeficijenti niski, najizraÅ¾enija korelacija izmeÄ‘u clicks_pre_start i i ocjene prvog zadatka, no dalje umjerena. Rezultati nam se podudaraju s Älankom.

# MODELI I REZULTATI

## Metrike

Q: Koje ste metrike koristili pri evaluaciji modela?

A:
- matrica zabune
    - TP, TN, FP, FN
    - brzi uvid u klasifikaciju skupa
    - vrijednosti koriÅ¡tene za druge metrike
    - preciznost - TP / (TP + FP)
    - odaziv - TP / (TP + FN)
- toÄnost
    - omjer ispravno klasificiranh primjera u odnosu na ukupan broj 
    - jednostavna za izraÄun, intuitivna
    - kod neuravnoteÅ¾enih skupova moÅ¾e zavaravati
- F1-score
    - harmonijska sredina preciznosti i odziva
    - dobra mjera kod neuravnoteÅ¾enih podataka
- ROC krivulja
    - odnos stope TP i FP za razliÄite pragove klasifikacije
    - uvid u ponaÅ¡anje pri razliÄitim pragovima klasifikacije
    - iz nje moÅ¾emo uÄitati optimalni prag - za BART smo to napravili
- AUC
    - povrÅ¡ina ispod ROC krivulje
    - vjerojatnost da Ä‡e model rangirati nasumiÄno odabrani pozitivni primjer viÅ¡lje od nasumiÄno izabranog negativnog

## Decision Tree
Q: Kako radi Decision Tree?
A: Dijeli podatke u hijerarhijske Ävorove prema kriteriju informacijske dobiti. Jednostavan je, ali sklon prenauÄenosti.

Q: Kako se Decision Tree ponaÅ¡ao na naÅ¡em skupu?
A:
- ukupna toÄnost: 0.39
- macro F1: 0.37
- najbolja klasa: Withdrawn
- najgora klasa: Distinction

Q: ZaÅ¡to su rezultati loÅ¡i za Distinction i Fail?
A: Zbog neuravnoteÅ¾enosti â€” stablo preferira veÄ‡inske klase i teÅ¡ko pronalazi granice za rijetke ishode. (ovo moÅ¾emo praktiÄki za svaki model reÄ‡)

## Random Forest
Q: ZaÅ¡to smo koristili Random Forest?
A: RF smanjuje varijancu kombiniranjem viÅ¡e stabala i bolje generalizira od pojedinaÄnog stabla.

Q: Koje su performanse Random Foresta?
A:
- ukupna toÄnost: 0.52
- macro F1: 0.43
- najbolje klasa: Withdrawn i Pass
- najgora klasa: Distinction

Q: Kako RF radi i zaÅ¡to je bolji od DT?
A:
- viÅ¡e stabala, uzima se klasa koju bira njih najiÅ¡e
- tijekom izgradnje stabala izbacuju se neke znaÄajke
- bolja generalizacija, smanjuje overfitting

## BART (Bayesian Additive Regression Trees)
Q: Kako radi BART?
A: BART je Bayesovski ansambl regresijskih stabala koji daje distribuciju predikcija, a ne samo jednu vrijednost. Radi u One-vs-Rest reÅ¾imu.

Q: Kako smo odreÄ‘ivali optimalni threshold?
A: Iz ROC krivulje

Q: Koji su rezultati BART modela?
A: 
- ukupna toÄnost: 0.69
- macro F1: 0.52
- najbolje klasa: Withdrawn i Pass
- najgora klasa: Distinction

## ğŸ“ˆ LogistiÄka regresija
Q: ZaÅ¡to smo koristili logistiÄku regresiju?
A: Kao baseline linearni model za usporedbu s nelinearnim modelima.

Q: Kako se LR ponaÅ¡ala na naÅ¡em skupu?
A:
- ukupna toÄnost: 0.57
- macro F1: 0.37
- najbolje klasa: Withdrawn i Pass
- najgora klasa: Distinction

Q: ZaÅ¡to LR loÅ¡e razdvaja Distinction i Pass?
A: Granica izmeÄ‘u tih klasa nije linearna â€” potrebni su nelinearni modeli poput RF, BART ili XGBoost.

## XGBoost - naÅ¡ pokuÅ¡aj koriÅ¡tenja novog modela
Q: ZaÅ¡to smo koristili XGBoost
A: SliÄna metoda metodama iz Älanka, joÅ¡ uvijek stvara stabla, htjeli smo usporediti ovu noviju metodu s veÄ‡ koriÅ¡etnima

Q: Kako se LR ponaÅ¡ala na naÅ¡em skupu?
A:
- ukupna toÄnost: 0.57
- macro F1: 0.44
- najbolje klasa: Withdrawn i Pass
- najgora klasa: Distinction

Q: Å to smo zakljuÄili iz rezultata

A: Uspjeli smo postiÄ‡i bolje rezultate od svih modela osim BART-a. Optimizacijom hiperparametara (Karlo) nismo uspjeli doÄ‡i do velikog poboljÅ¡anja. Ipak, treba napomenuti da je XGBoost puno brÅ¾i od BART-a, sliÄniji jednostavnijim modelima. Kada bi proveli viÅ¡e vremena uz optimizaciju hipermparametara i moÅ¾da dodatno uredili podatke kako bi viÅ¡e odgovarali modelu, vjerojatno bi mogli postiÄ‡i sliÄne rezultate BART-u, ali puno brÅ¾e.

ğŸ“‰ METRIKE I ANALIZA
## ğŸ¯ Accuracy
Q: ZaÅ¡to accuracy nije dobra metrika u ovom projektu?
A: Zbog neuravnoteÅ¾enosti â€” model moÅ¾e ignorirati male klase i svejedno imati visoku toÄnost.

## ğŸ¯ Precision
Q: Å to znaÄi visoka precision?
A: Model rijetko daje laÅ¾no pozitivne predikcije.

Q: Koja klasa ima najbolju precision?
A: Withdrawn (posebno kod Random Foresta).

## ğŸ¯ Recall
Q: Å to znaÄi visok recall?
A: Model uspjeÅ¡no pronalazi veÄ‡inu stvarnih pozitivnih primjera.

Q: Koja klasa ima najniÅ¾i recall u svim modelima?
A: Fail â€” najteÅ¾a klasa za predikciju.

## ğŸ¯ F1-score
Q: ZaÅ¡to je F1-score vaÅ¾an?
A: Kombinira precision i recall, posebno koristan kod neuravnoteÅ¾enih klasa.

## ğŸ¯ ROC i AUC
Q: Å to prikazuje ROC krivulja?
A: Odnos izmeÄ‘u TPR i FPR pri razliÄitim pragovima.

Q: Å to znaÄi AUC = 0.8?
A: Model Ä‡e u 80% sluÄajeva rangirati pozitivni primjer iznad negativnog.

Q: Koji model ima najbolje AUC rezultate?
A: BART

ğŸ§  ZAVRÅ NA PITANJA ZA PREDAJU
Q: Koji model biste odabrali kao najbolji?
A: BART, ali je dosta spor i zauzima puno memorije.

Q: Koja je najveÄ‡a slabost svih modela?
A: NeuravnoteÅ¾enost klasa, posebno Fail i Distinction.

Q: Kako biste poboljÅ¡ali rezultate?
A:

koristiti SMOTE (oversampling) - probali neuspjeÅ¡no
optimizirati hiperparametre (posebno za XGBoost) - probali neuspjeÅ¡no
dodati nove znaÄajke (npr. dinamika klikova kroz vrijeme) - nismo imali vremena